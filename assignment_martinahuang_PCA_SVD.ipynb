{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_name_PCA_SVD.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOTMwN5C20t1MtSQqKHvBo6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christoforou/cus615_lecture_code/blob/master/student_assignments/assignment_name_PCA_SVD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7H1KjiCex81",
        "colab_type": "text"
      },
      "source": [
        "## Workshop on using PCA\n",
        "This assignment is intended as a workshop to practice the use of Singular Value Decomposition and Principal Component Analysis as two ways to perform Matrix Factorization and Dimensionality Reduction. \n",
        "\n",
        "<div> By: Dr. Christoforos Christoforou </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VttSzIpsI3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdJsj33pEdlZ",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 1: Apply PCA on sample data - using numpy. \n",
        "In this section you need to apply PCA on a simulated dataset. You need to extract the prinipal components and use them to reduce the dimensionality of the data. For this challenge **do not use** sklearn library. Some starting code is provided for you in each cell. Complete all the exercises to earn all points in this challenge. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn4tJNf2rPf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Generate the dataset, split it into \n",
        "# \n",
        "rng = np.random.RandomState(4)     # Seed the random number generator.\n",
        "n_samples = 1000                    # Specify the number of samples. \n",
        "X_all = np.array([5,1,1,1,2]).T + np.dot(rng.rand(5, 5), rng.randn(5, n_samples)).T \n",
        "X_train, X_test = X_all[:n_samples//2,:],X_all[n_samples//2:,:] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvO7Si-XtY9_",
        "colab_type": "text"
      },
      "source": [
        "### Answer the following question.\n",
        "Use the cell below to find the answer to the following questions. \n",
        "\n",
        "- What is the dimensions of `X_train` and `X_test`?\n",
        "- How many `features` does each sample has (i.e. what is the dimensionality of the observations in data matrix X_all)?\n",
        "- Create three 2D scatter plots to show the relationship between to features-pairs (1,2), (1,4), (3,4)? Make sure you label each scatter plot. \n",
        "\n",
        "As an example, the following code create a scatter plot between the 1st and 3rd feature dimension\n",
        "```python \n",
        "plt.scatter(X_train[:,1],X_train[:,3])\n",
        "plt.title(\"Scatter plot between feature 2 and feature 4\")\n",
        "plt.xlabel(\"Feature 2\")\n",
        "plt.ylabel(\"Feature 4\")\n",
        "plt.axis(\"square\")\n",
        "\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkHb5BQIsCci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Use this cell to figure out the anwers to the questions above.\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1KCauPRufWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Display the scatter plot between the feature pairs (1,2), (1,4), (3,4) \n",
        "# \n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "# Plot the scatter plot between feature-pair (1,2) \n",
        "plt.subplot(1,4,1)\n",
        "plt.scatter(...)\n",
        "plt.title(...)\n",
        "plt.xlabel(...)\n",
        "plt.ylabel(...)\n",
        "plt.axis(\"square\")\n",
        "\n",
        "\n",
        "# Plot the scatter plot between feature-pair (1,4)\n",
        "plt.subplot(1,4,2)\n",
        "#\n",
        "# Your code here\n",
        "#\n",
        "plt.axis(\"square\")\n",
        "\n",
        "# Plot the scatter plot between feature-pair (3,4)\n",
        "plt.subplot(1,4,2)\n",
        "#\n",
        "# Your code here\n",
        "#\n",
        "plt.axis(\"square\")\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zySDhljMzba5",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1.1 : Calculate the covariance matrix.\n",
        "Calculate the covariance matrix of the training data matrix `X_train`. Show all you steps as outlined in the skeleton code provided. In particular, you need to \n",
        "calculate the observations' mean; subtract the mean from the data matrix; standardize the observations by dividing each feature with its corresponding standard deviation; and calculate the covarnace matrix. \n",
        "\n",
        "**Hints**\n",
        "  - Notice that you can find the mean of an array `A` along a particular dimension `b`, using the numpy command `np.mean(A,axis=b)`. In case `b=0` the mean is taken along the 0th dimension (i.e along the rows), when `b=1` the mean is taken along the 1st dimension (i.e. along the columns). Similarly, you can find the standard deviation of the array using the command `np.std(A,axis=b)` \n",
        "\n",
        "  - Python `broadcasting` allows you to perform artithmetic operation on arrays with different sizes, thus vectorizing the arithmetic operations and eliminates the need for using inefficent for loops. The following example shows how boradcasting is used to add  a row vector from every row in the 2D array.\n",
        "  ```python\n",
        "    # Example of using broadcasting\n",
        "    sample = np.array([[2,4], [10,-5]])\n",
        "    to_add = np.array([3,7])\n",
        "    sample_add_using_broadcasting  = sample + to_add \n",
        "    print(sample)\n",
        "    print(sample_add_using_broadcasting)\n",
        "  ``` \n",
        "  - The covariance matrix of a data matrix $X\\in \\mathbb{R}^{N\\times D}$(i.e. a matrix with $N$ rows/observations and $D$ columns/features is defined as \n",
        "    $\\frac{1}{N-1} X^T X$ where the term $\\frac{1}{N-1}$ is the normalization constant, and $^T$ denotes the matrix transpose. \n",
        "     In numpy, we can multiply two numpy arrays/matrices using the `np.matmul()` method and we can transpose a matrix by accessing the `.T`  property of the array (i.e. `np.matmul(X.T,X)`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlhdZ9y30qCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Calcualte the mean of X_train\n",
        "# \n",
        "\n",
        "X_mean = ...\n",
        "\n",
        "#\n",
        "# Subtract the mean from \n",
        "#\n",
        "\n",
        "X_train_mean_subtracted = ... \n",
        "\n",
        "# \n",
        "# Standarized observation to unit variance (i.e. divide by standard deviation)\n",
        "#\n",
        "\n",
        "X_std = ...\n",
        "X_train_std = ...\n",
        "\n",
        "\n",
        "#\n",
        "# Calculate the covariance of the standarized observations.\n",
        "# Make sure you use the appropripate normalization constant \n",
        "\n",
        "X_train_cov = ...\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aunT2XPB-RDW",
        "colab_type": "text"
      },
      "source": [
        "#### Answer the following questions:\n",
        "Use the cell below to answer the following questions and show your work.\n",
        "\n",
        "- Print the content of the covariance matrix.\n",
        "- What are the dimensions of the covariance matrix `X_train_cov` \n",
        "- What values do you see on the diagonal elements of the covariance matrix.\n",
        "- Which feature-pairs have the largest covariance value; what is that value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH7VfTR-2hvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Complete the code below to display a heatmap of the Covariance matrix \n",
        "#\n",
        "colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "sns.heatmap(...., cmap= colormap, annot=True, fmt=\".2f\")\n",
        "plt.title(\"Covariance Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#\n",
        "# Write code to find the answers to the questions in the cell above. \n",
        "#\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klhor9TMCr3e",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1.2: Estimate the Eigen-vectors and Eigen-values of the covariance matrix. \n",
        "The principal components of a covariance matrix are the eigen-vectors of the covariance matrix. The variance of each principal component is proportional to the eigen-value of its corresponding eigen-vector. \n",
        "\n",
        "As part of this exercise you need to extract the two the principal component of the covariance matrix that have the highest variance. Then answer the following questions. \n",
        "\n",
        "**Hints**\n",
        "- The numpy method `eigh` can be used to estimate the eighen-vectors and eigen-values of a square symetric matrix. For example, \n",
        "```python \n",
        "  a_symetric_square_matrix = np.array([[1,0.7],[0.7, 1]])\n",
        "  eig_vals, eig_vecs  = np.linalg.eigh(a_symetric_square_matrix)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By6WHK_qEDKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Calculate the eigenvectors and eigenvalues of the covariance matrix. \n",
        "# \n",
        "\n",
        "eig_vals, eig_vecs = ... \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x96Ndyh_Gych",
        "colab_type": "text"
      },
      "source": [
        "#### Answer the following questions. \n",
        "Use the code-cell below to find the answer to the following questions and show your work.\n",
        "- Print the eigen-vector with the largest eigen-value, also print the eigen-value itself, and the index of the vector in the `eig_vecs` matrix\n",
        "\n",
        "- Print the eigen-vector with the second largest eigen-value, also print the eigen-value itself, and the index of the vector in the `eig_vecs` matrix\n",
        "\n",
        "- Calculate the percentage of the variance in the data that is captured by the three eigen-vectors with the largest eigen-values.\n",
        "\n",
        "- Calculate the total variance captured by the two eigen-vectors with the smallest eigen-values. \n",
        "\n",
        "- What is the minimum number of principal component you can use to ensure that the least `85%` of the variance is captured in the reduced dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCkcuuiUFmKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d7f4a93-8f17-40f7-9127-0d79784ae0d3"
      },
      "source": [
        "#\n",
        "# Use this cell to find the answers to the above questions, and to show your work. \n",
        "#\n",
        "\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7172483592396515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iBcKBCqzGN1",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1.3 Dimensionality Reduction using Principal Components\n",
        "Use the principal component you calculated in the previous step to reduce the dimensionality of the feature space. \n",
        "\n",
        "- First, you must identify the two principal component with the highest variance (i.e. using the eigen-values you calculated in the previous code-cells).Then append the two principal components into their own matrix `PCA_mx` such that the metrix columns correspond to the selected Principal Components. \n",
        "\n",
        "- Use the resulting matrix `PCA_mx` to reduce the dimensions in the training set; from its original dimension down to two dimentions. You can do that by multiplying the *standaraized* training set X_train_std with the principal component's matrix `PCA_mx`. Store the resulting reduced-dimensionality training set into a variable `X_train_proj` \n",
        "\n",
        "- Use the resulting matrix `PCA_mx` to reduce the dimensions in the testing set; `X_test`. (*Hint: you must first standardize the testing set; using only quantities you calculated from the training set. Remember, standardization is the process of transforming the data to zero mean, and unit standard deviation*). Store the resulting reduced-dimensionality training set into a variable `X_test_proj`    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0JpkeNs0E1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#\n",
        "# Create a matrix whose columns are the two major principal component.\n",
        "# \n",
        "\n",
        "PCA_mx = ...\n",
        "\n",
        "#\n",
        "# Project the training set X_train onto the two major principal Components. \n",
        "# Use the matrix PCA_mx \n",
        "\n",
        "X_train_proj = ...\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1R4ldZx23Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Project the test dataset X_test onto the two major principal components\n",
        "# See hint for answering. \n",
        "# \n",
        "\n",
        "X_test_mean_subtracted = ...\n",
        "\n",
        "X_test_std = ...\n",
        "\n",
        "X_test proj = ... \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZcCqHDs2m-D",
        "colab_type": "text"
      },
      "source": [
        "#### Answer the following questions\n",
        "Use the code-cells below to find the anwers to the following question, and display the requested figures.\n",
        "\n",
        "- What is the shape of the matrix `X_train_proj` and what does each dimension represents. \n",
        "\n",
        "- What is the shape of the matrix `X_test_proj` and what does each dimension represents. \n",
        "\n",
        "- Display a scatter-plot showing the `X_train_proj` data.\n",
        "\n",
        "- Display a scatter-plot showing the `X_test_proj` data. \n",
        "\n",
        "- Calculate the covariance matrix of `X_train_proj` and identify what is the covariance between the first and second features. \n",
        "\n",
        "- Calculate the covariance matrix of `X_test_proj` and identify what is the covariance between the first and second features. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agy715Ih1yNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Use this code-cell to find the answer to the questions above. \n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atHscI6M_-3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Display the scatter-plots of the reduced-dimensional training and testing datasets.\n",
        "#\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(...)\n",
        "plt.title(\"Reduced-dimensional Training Set\")\n",
        "plt.axis('equal')\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(...)\n",
        "plt.title(\"Reduced-dimensional Test Set\")\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy7p3OPDBrHO",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 2: Apply PCA on sample data - Using the sklearn library\n",
        "\n",
        "Principal Component Analysis is often used as a pre-processing and dimenionality-reductiion step in predictive modeling. As such, the sklearn library provides a helper class that encapulates the step of extracting the principal component. \n",
        "\n",
        "Specifically, sklearn library provides the `PCA` class as part of its `sklearn.decomposition` module. You can clear a new instance of the PCA class as follows:\n",
        "```python \n",
        "  pca = PCA(n_components=2) \n",
        "```\n",
        "Notice the the variable `n_components` specifies the number of principal components we want to keep as part of the dimensionality reduction. \n",
        "\n",
        "To apply the PCA class, we must make sure that we standardize the dataset, that is to transform the data so they have zero mean and unit variance. Sklearn provides another helper function the  performnce the standardization of the data. The `StandardScaler` class, part of the `sklearning.preprocessing` module achieves that. For example, the following code would standardize a matrix X\n",
        "```python \n",
        "D = np.array([[1,2],[4,9],[1,5],[7,19],[4,9]])\n",
        "sc = StandardScaler()\n",
        "sc.fit_transform(D)        # Learn the standardization parameters (i.e. mean, std parameters)\n",
        "D_std = sc.transform(D)    # Standardize the dataset D\n",
        "\n",
        "np.cov(D_std.T, ddof=False)# Check the covariance matrix.\n",
        "```\n",
        "\n",
        "Once the dataset is standardized, we can extract the principal components using the `fit` method of the `PCA` class, for example using\n",
        "\n",
        "```python \n",
        "pca.fit(D_std)\n",
        "``` \n",
        "Notice that under the hood the fit method creates the covariance matrix, and solves the eigen-vector/eigen-value problem. \n",
        "\n",
        "The principal components (i.e. eigen-vectors) and their explained variance (i.e. corresponding eigen-value) can be retrived from the fitted `pca` instance through the `explained_variance_` and `components_` attributes, such as \n",
        "```python\n",
        "print(\"Extracted Principal Components (i.e. eigen-vectors\")\n",
        "print(pca.components_)\n",
        "\n",
        "print(\"Explained variabce of extracted components (i.e. eigen-values)\n",
        "print(pca.explained_variance_)\n",
        "```\n",
        "Finally, project a dataset onto the extracted principal components, we can use the `transform` method of the PCA class. For example,\n",
        "```python\n",
        "D_projected = pca.transform(D_std)\n",
        "``` \n",
        "**Exercise**\n",
        "Using the reference code above, extract the principal components of the same sample dataset (as the one in Challenge 1), but now using the helper classes provided in the sklearn library.  Moreover, reduce the dimensionality of the `X_train` and `X_test` dataset by projecting to the two major principal components. \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L36yCl5XIC4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the sklearn libaries \n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing importStandardScaler "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ChRGsXkH0_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Create an Instance of the PCA class from sklearn.decomposition import PCA\n",
        "#\n",
        "\n",
        "pca = ...\n",
        "\n",
        "\n",
        "#\n",
        "# Standardize the training and testing dataset. \n",
        "#\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train_std = ...\n",
        "\n",
        "\n",
        "#\n",
        "# Extract/learn the principal components\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "# Project the train dataset onto the two major principal components. \n",
        "#\n",
        "\n",
        "X_train_proj_sklearn = ...\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "# Project the train dataset onto the two major principal components. \n",
        "# Hint: do not forget to standardize the test dataset. \n",
        "\n",
        "X_test_proj_sklearn = ...\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU8NQ-6XWMM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "#  Display a scatter-plot showing the `X_train_proj_sklearn` data.\n",
        "#\n",
        "#  Display a scatter-plot showing the `X_test_proj_sklearn` data. \n",
        "#. Hint: See sample code from Challenge 1.\n",
        "#  \n",
        "\n",
        "\n",
        "# your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UlytNdsDvCR",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 3: Perform PCA to reduce the dimensions of the wine dataset.\n",
        "\n",
        "The code-cell below load an example dataset called `wine.data` as a panda's dataframe, and then split it into a training `X_train` and testing dataset `X_test`. Each observation corresponds to a particular wine brand and the features correspond to various characteristics associated with each wine (for example, 'Alcohol', 'Malic acid', 'Ash','Alcalinity of ash', 'Magnesium'). There are total 13 such features for each wine. Moreover, each wine belongs to one of three quality classes (i.e. 1,2 or 3). The class labels for each onservation are stored in the `y_train` and `y_test` vectors. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSGeoxykeq_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
        "                      'machine-learning-databases/wine/wine.data',\n",
        "                      header=None)\n",
        "\n",
        "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
        "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
        "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
        "                   'Color intensity', 'Hue',\n",
        "                   'OD280/OD315 of diluted wines', 'Proline']\n",
        "                   \n",
        "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
        "                     stratify=y,\n",
        "                     random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5nSaaf9fqLJ",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 3.1  \n",
        "\n",
        "Your goal is to find a classifier to predict the quality class of a wine, given its observed features. You suspect that several of the features covay and that you are better off to reduce the number of dimession of the same before performing the classificaton.\n",
        "\n",
        "In this exercise you are expected to use PCA to reduce the dimensionality of the original dataset from 13 down to two. Then use the K-NN to train a classifier that predicts the wine quality class. \n",
        "\n",
        "Compare the performance of your classifier, to a classifier that uses all 13 features. You must report cross validation performance, and independent test performance. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lr6NJsngXm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Use as many code-cell you deem necessary to complete exercise 3.1\n",
        "# Make sure you add comments, to explain your code. \n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTeztEgfgXbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL2rcSRffzI6",
        "colab_type": "text"
      },
      "source": [
        "#### Summarize the results of your analysis on the wine Dataset.\n",
        "Use the following text-cell to summarize the results of your analysis. For example, consider the following questions: which classifer performces better and by how match? Did PCA dimensionallity reduction helped imporove the classification performance or not? Should you have used more or less principal components to improve classification performance. How much of the variance is captured by the reduced feature space? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3zFiik2gQjL",
        "colab_type": "text"
      },
      "source": [
        "#### Your results summary here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp13E0NubG77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzQMvN1Mi8zA",
        "colab_type": "text"
      },
      "source": [
        "## License \n",
        "\n",
        "<div> This workbook is prepare by Dr. Christoforos Christoforou for the purposed of course. If you identify any typos/errors please let the author know. Not for circulation outside the course</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFr8UHJfjS--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}