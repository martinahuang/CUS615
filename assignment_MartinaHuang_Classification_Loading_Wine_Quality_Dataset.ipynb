{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "assignment_yourname_Classification_Loading_Wine_Quality_Dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinahuang/CUS615/blob/master/assignment_MartinaHuang_Classification_Loading_Wine_Quality_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYRWDeowYXCj",
        "colab_type": "text"
      },
      "source": [
        "# Wine Quality Dataset \n",
        "\n",
        "## Data Description\n",
        "\n",
        "### Red Wine Quality - Parameters\n",
        "* fixed.acidity (tartaric acid - g / dm^3): most acids involved with wine or fixed or nonvolatile (do not evaporate readily) \n",
        "* volatile.acidity (acetic acid - g / dm^3): the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste \n",
        "* citric.acid (g / dm^3): the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste \n",
        "* residual.sugar (g / dm^3): the amount of sugar remaining after fermentation stops, it's rare to find wines with less than 1 gram/liter and wines with greater than 45 grams/liter are considered sweet \n",
        "* chlorides (sodium chloride - g / dm^3): the amount of salt in the wine \n",
        "* free.sulfur.dioxide (mg / dm^3): the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine \n",
        "* total.sulfur.dioxide (mg / dm^3): amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine \n",
        "* density (g / cm^3): the density of water is close to that of water depending on the percent alcohol and sugar content \n",
        "* pH: describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale \n",
        "* sulphates (potassium sulphate - g / dm3): a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich acts as an antimicrobial and antioxidant \n",
        "* alcohol (% by volume): the percent alcohol content of the wine \n",
        "* quality: quality score between 0 and 10\n",
        "\n",
        "### Objective.\n",
        "\n",
        "* To explore the physiocochemical properties of red wine\n",
        "* To determine an optimal machine learning model for red wine quality classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qkkCRy9YXCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import librarires\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Sklearn moduels.\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVgBGUS0YXCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Include any additional modules libraries your code might need here.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBt65lyHYih3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture \n",
        "\n",
        "# Execute this cell first to download the necessary data \n",
        "# This cell installs sample data necessary for this workshow on your colab virtual enviroment\n",
        "!wget -O /content/sample_data/wineQualityReds.csv https://raw.githubusercontent.com/christoforou/intro_to_pandas_lab/master/data/red-wine-dataset/wineQualityReds.csv\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpsj8s3DYXCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to load the data from file. Here we use the pandas library to read the csv file. \n",
        "datafile = \"./sample_data/wineQualityReds.csv\"\n",
        "wine_df = pd.read_csv(datafile)\n",
        "wine_df.drop(wine_df.columns[0],axis=1,inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqL0XWrqYXCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into a training and testing set using the sklearn function train_test_split\n",
        "# Noteice that \n",
        "X_train, X_test, y_train, y_test = train_test_split(wine_df.drop('quality',axis=1), wine_df['quality'], test_size=.25, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA3vk26dYXC2",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 1\n",
        "Use the variables `X_train`, `X_test`, `y_train`, and `y_test` to explore your data. In particular, calculate and display the following information.\n",
        "\n",
        "* Number of samples in the training set in total and in each class.\n",
        "* Number of samples in the testing set in total and in each class.\n",
        "* Number of features in the dataset. \n",
        "* Number of classes in the dataset.\n",
        "* IDs of the number of classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiXoK_qwYXC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd6a6e5b-bd85-455d-bb16-6133bfdc2b7e"
      },
      "source": [
        "# Your Solution here\n",
        "X_train.shape\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1199, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrI6VnqPdhp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20fe6e59-5cf5-4ec6-e9b1-28e44f2223d8"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnAufkhhi1z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = len(np.unique(X_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXzca_yvd9w5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9604d14-98e0-4358-e098-c33cbeb5b749"
      },
      "source": [
        "str(n_features)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1033'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaLAdMeIjWN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c463b148-e59f-434c-ebee-4dcf2c57a9d5"
      },
      "source": [
        "n_samples_train, n_features = X_train.shape\n",
        "n_samples_test, _ = X_test.shape\n",
        "n_features = len(np.unique(y_test))\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "print(\"Number of samples in training set: %d ( %d positive, %d negative)\" % (n_samples_train,np.sum(y_train==1),np.sum(y_train==0)))\n",
        "print(\"Number of samples in the testing set: %d (%d positive, %d negative)\" % (n_samples_test,np.sum(y_test==1),np.sum(y_test==0)))\n",
        "print(\"Number of features: \" +  str(n_features))\n",
        "print(\"Number of classes: \" + str(n_classes))\n",
        "print(\"IDs for class labels: \" + str(np.unique(y_train)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples in training set: 1199 ( 0 positive, 0 negative)\n",
            "Number of samples in the testing set: 400 (0 positive, 0 negative)\n",
            "Number of features: 2\n",
            "Number of classes: 2\n",
            "IDs for class labels: ['Bad' 'Good']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiI3psnpYXC7",
        "colab_type": "text"
      },
      "source": [
        "# Challenge 2\n",
        "\n",
        "Train a k-NN classifier using the `(X_train,y_train)` dataset and use the trained model to predict the underlying classes for the observations in the test dataset `X_test`. Store your prediction in a variable called `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt71_xYAeKu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KNeighborsClassifier(n_neighbors=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tDPvqsfeKti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqyJrw2vYXC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your solution \n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_true = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXzRoS9zYXDA",
        "colab_type": "text"
      },
      "source": [
        "# Challenge 3\n",
        "\n",
        "Evaluate the performance of your classifier. Calculate and display the following:\n",
        "* print the `confusion matrix`.\n",
        "* `normalized confusion matrix`. \n",
        "* the probablitity of correct classification (accuracy score). \n",
        "* the `precision`, `recall`, and `f1-score` for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLY8dmj9YXDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "091b2fe6-8817-4e47-f391-e0b99e111f8c"
      },
      "source": [
        "# Your solution \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"\\n This is the confusion matrix\")\n",
        "cnf_mx = metrics.confusion_matrix(y_true, y_pred)\n",
        "print(cnf_mx)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " This is the confusion matrix\n",
            "[[ 0  0  1  0  0  0]\n",
            " [ 0  1  3  8  1  0]\n",
            " [ 1 12 98 48  4  1]\n",
            " [ 0 15 74 62 18  0]\n",
            " [ 0  0 10 21 15  2]\n",
            " [ 0  0  1  2  2  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vg-wLKlmDNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "52cf41dc-5867-4250-dcb9-ec549afb4404"
      },
      "source": [
        "print(\"\\n This is the normalized confusion matrix.\")\n",
        "cnf_mx_joint = cnf_mx.astype('float')/ cnf_mx.sum()\n",
        "print(cnf_mx_joint)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " This is the normalized confusion matrix.\n",
            "[[0.     0.     0.0025 0.     0.     0.    ]\n",
            " [0.     0.0025 0.0075 0.02   0.0025 0.    ]\n",
            " [0.0025 0.03   0.245  0.12   0.01   0.0025]\n",
            " [0.     0.0375 0.185  0.155  0.045  0.    ]\n",
            " [0.     0.     0.025  0.0525 0.0375 0.005 ]\n",
            " [0.     0.     0.0025 0.005  0.005  0.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgzDuH2jmp5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5dce330-190a-4ea7-8d00-a8f0006ce6e5"
      },
      "source": [
        "# Accuracy.\n",
        "#\n",
        "acc = metrics.accuracy_score(y_true, y_pred)\n",
        "# Display the output\n",
        "print(\"Accuracy: %.3f\" % acc)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4Tr9tQ-msM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c4aeb725-7156-41db-c771-f2eb69f2bd5a"
      },
      "source": [
        "target_names = ['Negative', 'Positive']\n",
        "print(metrics.classification_report(y_true,y_pred,target_names=target_names))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.57      0.61      0.59       178\n",
            "    Positive       0.67      0.63      0.65       222\n",
            "\n",
            "    accuracy                           0.62       400\n",
            "   macro avg       0.62      0.62      0.62       400\n",
            "weighted avg       0.62      0.62      0.62       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tISC_CuuYXDE",
        "colab_type": "text"
      },
      "source": [
        "# Challenge 4\n",
        "\n",
        "The code below loads the same dataset, by treats it as a binary classification problem. That is, instead of classifying an observation into one of 10 categories (0..10), we consider all observations with score above 5 as being good and all observation below or equal to five as being bad.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOknQCteYXDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to load the data from file. Here we use the pandas library to read the csv file. \n",
        "datafile = \"./sample_data/wineQualityReds.csv\"\n",
        "wine_df = pd.read_csv(datafile)\n",
        "wine_df.drop(wine_df.columns[0],axis=1,inplace=True)\n",
        "\n",
        "wine_df['quality'] = np.where(wine_df['quality']>5,\"Good\",\"Bad\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbQmpDuKYXDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(wine_df.drop('quality',axis=1), wine_df['quality'], test_size=.25, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1YJhHoYXDM",
        "colab_type": "text"
      },
      "source": [
        "## Callenge 4.1\n",
        "Use the variables `X_train`, `X_test`, `y_train`, and `y_test` to explore your data. In particular, calculate and display the following information.\n",
        "* Number of samples in the training set in total and in each class.\n",
        "* Number of samples in the testing set in total and in each class.\n",
        "* Number of features in the dataset. \n",
        "* Number of classes in the dataset.\n",
        "* IDs of the number of classes.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSm4hG_xYXDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "219d4860-146c-430a-98cc-649a8b7a8b54"
      },
      "source": [
        "# Your Solution \n",
        "n_samples_train, n_features = X_train.shape\n",
        "n_samples_test, _ = X_test.shape\n",
        "n_features = len(np.unique(y_test))\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "print(\"Number of samples in training set: %d ( %d positive, %d negative)\" % (n_samples_train,np.sum(y_train==1),np.sum(y_train==0)))\n",
        "print(\"Number of samples in the testing set: %d (%d positive, %d negative)\" % (n_samples_test,np.sum(y_test==1),np.sum(y_test==0)))\n",
        "print(\"Number of features: \" +  str(n_features))\n",
        "print(\"Number of classes: \" + str(n_classes))\n",
        "print(\"IDs for class labels: \" + str(np.unique(y_train)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples in training set: 1199 ( 0 positive, 0 negative)\n",
            "Number of samples in the testing set: 400 (0 positive, 0 negative)\n",
            "Number of features: 2\n",
            "Number of classes: 2\n",
            "IDs for class labels: ['Bad' 'Good']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dp5WBluYXDQ",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 4.2 \n",
        "Train a k-NN classifier using the `(X_train,y_train)` dataset and use trained model to predict the underlying classes for the observations in the test dataset `X_test`. Store your prediction in a variable called `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVFLojbcYXDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your solution \n",
        "model = KNeighborsClassifier(n_neighbors=3)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_true = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX1MGX3bYXDT",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 4.3\n",
        "Evaluate the performance of your classifier. Calculate and display the following:\n",
        "* print the `confusion matrix`.\n",
        "* `normalized confusion matrix`. \n",
        "* the probablitity of correct classification (accuracy score). \n",
        "* the `precision`, `recall`, and `f1-score` for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hoUdKozYXDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "18bd9c59-8409-476d-838f-e063538b56e0"
      },
      "source": [
        "# Your Solution \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"\\n This is the confusion matrix\")\n",
        "cnf_mx = metrics.confusion_matrix(y_true, y_pred)\n",
        "print(cnf_mx)\n",
        "\n",
        "print(\"\\n This is the normalized confusion matrix.\")\n",
        "cnf_mx_joint = cnf_mx.astype('float')/ cnf_mx.sum()\n",
        "print(cnf_mx_joint)\n",
        "\n",
        "\n",
        "# Accuracy.\n",
        "acc = metrics.accuracy_score(y_true, y_pred)\n",
        "# Display the output\n",
        "print(\"Accuracy: %.3f\" % acc)\n",
        "\n",
        "target_names = ['Negative', 'Positive']\n",
        "print(metrics.classification_report(y_true,y_pred,target_names=target_names))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " This is the confusion matrix\n",
            "[[108  70]\n",
            " [ 82 140]]\n",
            "\n",
            " This is the normalized confusion matrix.\n",
            "[[0.27  0.175]\n",
            " [0.205 0.35 ]]\n",
            "Accuracy: 0.620\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.57      0.61      0.59       178\n",
            "    Positive       0.67      0.63      0.65       222\n",
            "\n",
            "    accuracy                           0.62       400\n",
            "   macro avg       0.62      0.62      0.62       400\n",
            "weighted avg       0.62      0.62      0.62       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouqRqJw1YXDZ",
        "colab_type": "text"
      },
      "source": [
        "# Challenge 5\n",
        "\n",
        "Knn classifier accepts a number of parameters. Once of those parameters is the number K (i.e. the number of nearest neighbors to consider when making a prediction. Evaluate the classifier for different values of K and identify which configuration achieve the best performance on the testing set. Plot or print your results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FinafW1YXDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "aa59b50d-ffb6-43c2-efbb-55d1f52e011f"
      },
      "source": [
        " \n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-49adbff0aca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'K '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/seaborn/relational.py\u001b[0m in \u001b[0;36mscatterplot\u001b[0;34m(x, y, hue, style, size, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, x_bins, y_bins, units, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \u001b[0mx_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_bins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m         \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_jitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_jitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_jitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_jitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1405\u001b[0m     )\n\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/seaborn/relational.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, size, style, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, x_bins, y_bins, units, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         plot_data = self.establish_variables(\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         )\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/seaborn/relational.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, size, style, units, data)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not interpret input '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# Extract variable names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Could not interpret input ' x'"
          ]
        }
      ]
    }
  ]
}