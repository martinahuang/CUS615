{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Final_Exam_Project_CUS615.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TKJldPiWY5Tr",
        "CPCmSbfCcs4P",
        "3cPhHjAdciZP",
        "YJa9qQVr1vmv",
        "Lp0BpsHd4wfg",
        "2D6o6Cy-8xKp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinahuang/CUS615/blob/master/Copy_of_Final_Exam_Project_CUS615.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I81n6Tk2bTd3",
        "colab_type": "text"
      },
      "source": [
        "This notebook is part the of **Dr. Christoforos Christoforou's** course materials. You may not, nor may you knowingly allow others to reproduce or distribute lecture notes, course materials or any of their derivatives without the instructor's express written consent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJd26bpK54JR",
        "colab_type": "text"
      },
      "source": [
        "# Final Exam Project\n",
        "**Professor**: Dr. Christoforos Christoforou\n",
        "\n",
        "The objective of this project is to reproduce the data analysis method presented in the paper:\n",
        "\n",
        "* **\"Mining Big Data to Extract Patterns and Predict Real-Life Outcomes\"**\n",
        "by Michal Kosinski, Yilun Wang, Himabindu Lakkaraju, and Jure Leskovec.\n",
        "\n",
        "\n",
        "You must implement the analysis using python code. This notebook provides you with the starting code to load the data and guides you through the requirement and each sub-task of the analysis. To complete this project you are expected to:\n",
        "\n",
        "1. Carefully read the paper.\n",
        "2. Refer the class lecture where this paper was discussed in detail.\n",
        "3. Research various python libraries and utility functions needed to implement your analysis.\n",
        "4. Complete all the challenges outlined in this notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA45dOL-iEkE",
        "colab_type": "text"
      },
      "source": [
        "## Student Information \n",
        "Complete your information in the form provided below. This is visible in colab. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaAt15_OiVnw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Strudent Information \n",
        "student_name = \"Martina Huang\" #@param {type:\"string\"}\n",
        "course_code = \"CUS 615 -CRN: 12094\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqGbeNmFGCCU",
        "colab_type": "text"
      },
      "source": [
        "## Starter code - Configuring the analysis environment\n",
        "The code cells below provide you a starting code to setup the environment for you to complete this project's tasks.\n",
        "\n",
        "In particular, the code downloads the three dataset associated with this project and stores them in the folder `/content/sample_data/`. The data files from the paper comprise the `likes.csv` file, the `users.csv` file and the `users-likes.csv`; description of each data file is availabile in the paper.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB33C_sJ5p4H",
        "colab_type": "code",
        "outputId": "300651e2-b1d5-4fd3-d164-d71778d6b09a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "#\n",
        "# Run this sell to download the data for your analysis. \n",
        "#\n",
        "!wget -O /content/sample_data/sample_dataset.zip https://osf.io/9m87k/download\n",
        "!unzip /content/sample_data/sample_dataset.zip -d /content/sample_data/\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-03 21:20:16--  https://osf.io/9m87k/download\n",
            "Resolving osf.io (osf.io)... 35.190.84.173\n",
            "Connecting to osf.io (osf.io)|35.190.84.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://files.osf.io/v1/resources/fuqjg/providers/osfstorage/5e946850f1353503a3d52f24?action=download&direct&version=1 [following]\n",
            "--2020-05-03 21:20:16--  https://files.osf.io/v1/resources/fuqjg/providers/osfstorage/5e946850f1353503a3d52f24?action=download&direct&version=1\n",
            "Resolving files.osf.io (files.osf.io)... 35.186.214.196\n",
            "Connecting to files.osf.io (files.osf.io)|35.186.214.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 314322145 (300M) [application/octet-stream]\n",
            "Saving to: ‘/content/sample_data/sample_dataset.zip’\n",
            "\n",
            "/content/sample_dat 100%[===================>] 299.76M  17.7MB/s    in 19s     \n",
            "\n",
            "2020-05-03 21:20:36 (16.2 MB/s) - ‘/content/sample_data/sample_dataset.zip’ saved [314322145/314322145]\n",
            "\n",
            "Archive:  /content/sample_data/sample_dataset.zip\n",
            "replace /content/sample_data/likes.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_k8ynI123ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Install additional package not available in colab.\n",
        "#\n",
        "pip install factor_analyzer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO_u3jLnJ6ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# You will likely need the following python packages when implementing this project.\n",
        "# Add any additional package as you deem necessary \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds, eigs\n",
        "from factor_analyzer import Rotator\n",
        "\n",
        "# Additional package you want to use:\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc6GFQPhKTUn",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 1 : Load the data into dataframes\n",
        "In this challenge you are expected to load the data from the raw files into the following variables:\n",
        "-  `users` : should reference a dataframe with the data in the `users.csv` file\n",
        "-  `likes` : should reference a dataframe with the data in the `likes.csv` file\n",
        "-  `ul` : should reference a dataframe with the data in `users.csv` file\n",
        "\n",
        "Then print the top 10 rows of reach dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7jYTqf_Mabo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code goes here \n",
        "# \n",
        "\n",
        "datafile1 = './sample_data/likes.csv'  \n",
        "datafile2 =  './sample_data/users.csv'  \n",
        "datafile3 = './sample_data/users-likes.csv'\n",
        "\n",
        "likes = pd.read_csv(datafile1)\n",
        "users = pd.read_csv(datafile2)\n",
        "ul = pd.read_csv(datafile3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlspDtjMf89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Answer summary cell: Print the top 10 row from each datafame. \n",
        "# \n",
        "likes.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDwjd2OE-9g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLHrH5Js_B7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ul.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJYv5EFuMfkL",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 2: Create the sparse user-likes matrix \n",
        "Create a **sparse matrix** that stores the data for the user-likes associations as described in the paper. The name of the user-likes matrix must be `M`, to keep the naming convention used in the paper. It is important that to store the data in a sparse matrix; you might need to research the topic of using sparse matrices in python (i.e. look at the `scipy.sparse` package and the `csr_matrix` class). *Hint: For this challenge,  you might find  the `merge` method from `pandas` library useful*. \n",
        "\n",
        "Once you create the matrix print its shape on the answer summary cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnI9ocfkYox-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merge the files first then matrix\n",
        "# Your code goes here.\n",
        "# \n",
        "ul1 = pd.merge(likes, ul , on = 'likeid' ,)\n",
        "ul2 = pd.merge (users, ul , on = 'userid')\n",
        "print(ul)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAjo7_3SWcv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ul.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1oBOMpoWJtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#M = csr_matrix ()\n",
        "\n",
        "M = csr_matrix(ul, ('userid','likeid'))\n",
        "print (M)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDuZJyKKXSom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckYGEacxYvho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Answer summary cell:  Print the shape of the matrix M\n",
        "# \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKJldPiWY5Tr",
        "colab_type": "text"
      },
      "source": [
        "## Challege 3: Trim the sparse user-likes matrix M.\n",
        "The paper calls for the matrix `M` to be trimmed (i.e. to remove users which did not like a minimum number of posts and posts that did not receive a minimum number of likes). In this challenge, you are expected to implement the trimming preprocessing step as described in the paper. The resulting matrix must be a sparse matrix. *Hint: you might want to research to index slice sparse matrices in python*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_M8CC9-cXZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Your code here. \n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ywuRl88caaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Answer summary cell:  Print the shape of the matrix M after trimming. \n",
        "# \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPCmSbfCcs4P",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 4:  Split the sparse matrix into a training and testing matrices\n",
        "To build a prediction model the paper calls for separating the data matrix (i.e. the user-like matrix) into a training and testing matrices. As part of this challenge, you need to create a training matrix `M_train` that includes the preferences of 80% of the users, and a testing matrix `M_test` that include the preferences of the remaining 20% of the users in the dataset. Both matrices `M_train` and `M_test` must be stored as sparse matrices. User will be randomly assigned to the training or testing set.\n",
        "\n",
        "Print the shapes of the `M_train` and `M_test` matrices.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1avbiXTygvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Your code here. \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbTijUQ0ykDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Answer summary cell: Print the shapes of M_train, M_test and M matrices.  \n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cPhHjAdciZP",
        "colab_type": "text"
      },
      "source": [
        "## Challege 5 : Reduce the dimensionality of the M_train matrix using SVD\n",
        "\n",
        "In this challenge, you must use singular value decomposition (SVD) to reduce the dimensionality of the training matrix `M_train`. Remember that `M_train` is encoded as a sparse matrix so you would need to use an appropriate implementation of the SVD for sparse matrices. Your output should be the matrices `U`, `S` and `Vt` that correspond to the left singular vectors, the singular values, and the right singular vectors, respectively. You must specify a parameter `k` that defines the number of reduced dimensions you want to keep.\n",
        "\n",
        "Print the shapes of the `U`, `S` and `Vt` matrices and the value you selected for parameter `k`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--NlzhH21mWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Your code here. \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEtb9wsn1mzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Answer summary cell: Print the shapes of U, S and Vt; and the value you selected for parameter `k`.\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJa9qQVr1vmv",
        "colab_type": "text"
      },
      "source": [
        "## Challege 6 : Use the varimax algorithm to rotate the SVD dimensions. \n",
        "Use the varimax algorithm to rotate the SVD dimensions as described in the paper. A good python library that implements varimax algorithm is the `factor_analyzer` and its `Rotator` class (already installed in this notebook for your in the started cell above); i.e. using `rotator = Rotator(method='varimax')`. Store the varimax SVD into the matrices `U_rot` and `V_rot` respectively. *Hint: you can apply varimax of `Vt` to get `V_rot` and then multiply `M` by  `Vt_rot` to obtain the `U_rot` (as done in the paper); you might want to research hot to user the `Rotator` class*. \n",
        "\n",
        "Print the shapes of the matrices `U_rot` and `V_rot`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxGmf_MN4KH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Your code here. \n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_2U3n2X4h_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Answer summary cell: Print the shapes of the matrices `U_rot` and `V_rot`\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp0BpsHd4wfg",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 7 : Train two predictive model to predict the political  affilication of users.\n",
        "Build a predictive model that predicts the political affiliation of the users given the user's post preferences (as those are captured in the paper's dataset). To train your model you can use data from matrix `M_train` only. You are expected to use two different predictive models of your choice (i.e. Knn, SVM, Logistic Regression or some other model of your choice).\n",
        "\n",
        "As part of this challenge you are expected to:\n",
        "- Apply any necessary preprocessing to handle missing values.\n",
        "- The models must be applied on the reduced-dimensional feature generated by your analysis above (i.e. use the singular rotated singular dimensions)\n",
        "- Use cross-validation for model selection (i.e. to identify optimal parameters for your model, or any meta-parameters)\n",
        "- Report training and cross-validation performance of the two models as well as the optimal parameters for your model identified by cross validation. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiQ_wRcs7pA7",
        "colab_type": "text"
      },
      "source": [
        "**FIRST MODEL TRAINING: Use the cells below to train the predictive model using the first model you selected.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK6Yd4hf7fAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Use this cell to train the first model you selected for challenge 7. \n",
        "# Add additional cells as needed below this cell.\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHxGNOFf83pO",
        "colab_type": "text"
      },
      "source": [
        "**FIRST MODEL ACCURACY REPORT: Use the cell below to report on the accuracy of your first model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDrzCnB99i9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Use this cell to report on the accuracy of the first model (i.e. training and cross validation performance)\n",
        "# and model selection results. \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrkRGd1t-ISp",
        "colab_type": "text"
      },
      "source": [
        "**SECOND MODEL TRAINING: Use the cells below to train the predictive model using the second model you selected.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR8wUcci-Lnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Use this cell to train the second model you selected for challenge 7. \n",
        "# Add additional cells as needed below this cell.\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RcnRV85-SkD",
        "colab_type": "text"
      },
      "source": [
        "**SECOND MODEL ACCURACY REPORT: Use the cell below to report on the accuracy of your second model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DxNn4gl-SCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Use this cell to report on the accuracy of the second model (i.e. training and cross validation performance)\n",
        "# and model selection results.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D6o6Cy-8xKp",
        "colab_type": "text"
      },
      "source": [
        "## Challenge 8 Apply your model in the independent test set.\n",
        "User the cells below to apply your two predictive models on the test dataset `M_test` and report testing accuracy for each model.\n",
        "\n",
        "As part of this challenge you are expected to:\n",
        "- Project each observation in the test dataset `M_test` onto the reduced-dimensional features space.\n",
        "- Apply each on of your model to make predict each user's political preference (for users in the testing set only)\n",
        "- Report testing accuracy on each of your models.\n",
        "- Make an assessment as to which model is better and whether either of your models is overfitted or under-fitted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtC0osVlCgr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Use this cell to comlete challege 8; add more cells as necessary. \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqDyqK9qb4Ze",
        "colab_type": "text"
      },
      "source": [
        "# END OF EXAM/CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha290eSXRT9R",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*Copyright Statement*: Copyright © 2020 Christoforou. The materials provided by the instructor of this course, including this notebook, are for the use of the students enrolled in the course. Materials are presented in an educational context for personal use and study and should not be shared, distributed, disseminated or sold in print — or digitally — outside the course without permission. You may not, nor may you knowingly allow others to reproduce or distribute lecture notes, course materials  as well as any of their derivatives without the instructor's express written consent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp_ijPXabKsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}